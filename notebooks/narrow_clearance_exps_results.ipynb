{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyzing MC-results for clearance experiments (and last-mile computations)\n",
    "\n",
    "Here, we'll take the raw outputs from the experiments and post-process them into the final Monte-Carlo results we'll be looking for.\n",
    "An entry of one MC-iteration is the relevant experiment params (clearance, n_samples in the PRM, dimension), and the `threshold' number of neighbors/radius to find a feasible path (fewer neighbors/shorter results in no path solve). \n",
    "\n",
    "This allows is to use the threshold to compute the probability of a wide range of radii/neighbors (have a discrete grid of radii/neighbors, increment the ones above the threshold)."
   ],
   "id": "57288162350f192c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:36:55.098262Z",
     "start_time": "2024-05-30T14:36:55.094391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd ~/Research/nonasymptotic-mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools as it\n",
    "import json\n",
    "import glob\n",
    "import os"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seiji/Research/nonasymptotic-mp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:36:55.105390Z",
     "start_time": "2024-05-30T14:36:55.099054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load in the experiment and set plotting params\n",
    "exp_name = 'narrow-full-run9_20240522-081521'\n",
    "exp_path = os.path.join('exps', 'results', exp_name)\n",
    "\n",
    "n_radii = 100"
   ],
   "id": "89cb4644874fcdd4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading in the experiment log:",
   "id": "fd54f33bcd684701"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:36:55.132134Z",
     "start_time": "2024-05-30T14:36:55.106091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_paths = glob.glob(os.path.join(exp_path, 'out*.csv'))\n",
    "out_df = pd.concat(map(lambda x: pd.read_csv(x, index_col=0), out_paths))\n",
    "\n",
    "exp_config = json.load(open(os.path.join(exp_path, 'config.json'), 'r'))\n",
    "max_rad = exp_config['radius_prm_max_radius']\n",
    "max_knn = exp_config['knn_prm_max_neighbors']\n",
    "\n",
    "rads = np.linspace(out_df['conn_lb'].min(), max_rad, num=n_radii)"
   ],
   "id": "51ca9c7db0014797",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Doing the MC-computation for radius/knns",
   "id": "ba7e98853fb9ee90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:36:55.262691Z",
     "start_time": "2024-05-30T14:36:55.133410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first prep the corresponding counters for all the mc trials. \n",
    "# we'll do a relatively naive dictionary-type thing, and convert floats to strings to use as keys\n",
    "# create iterators for each experiment type and stack them together\n",
    "radius_trials_iter = it.product(\n",
    "    ['radius'],  # need this for proper indexing into the pandas array\n",
    "    exp_config['deltas'],\n",
    "    exp_config['dims_to_test'],\n",
    "    exp_config['radius_sample_schedule'],\n",
    ")\n",
    "\n",
    "knn_trials_iter = it.product(\n",
    "    ['knn'],  # need this for proper indexing into the pandas array\n",
    "    exp_config['deltas'],\n",
    "    exp_config['dims_to_test'],\n",
    "    exp_config['knn_sample_schedule'],\n",
    ")\n",
    "\n",
    "all_trials_iter = it.chain(radius_trials_iter, knn_trials_iter)\n",
    "estimate_dict = {}\n",
    "\n",
    "for prm_type, clearance, dim, n_samples in all_trials_iter:\n",
    "    _clearance = str(clearance)\n",
    "\n",
    "    # filter for the specific trial type\n",
    "    mc_trial_rows = out_df[\n",
    "        (out_df['prm_type'] == prm_type) &\n",
    "        (out_df['dim'] == dim) &\n",
    "        np.isclose(out_df['delta_clearance'], clearance) &\n",
    "        (out_df['n_samples'] == n_samples)\n",
    "        ]\n",
    "\n",
    "    if prm_type == 'knn':\n",
    "        conn_thresh_arr = np.tile(\n",
    "            mc_trial_rows['conn_ub'].to_numpy().reshape(-1, 1),\n",
    "            (1, max_knn)\n",
    "        )\n",
    "        conn_cmp_arr = np.tile(np.arange(max_knn), (conn_thresh_arr.shape[0], 1))\n",
    "    else:\n",
    "        conn_thresh_arr = np.tile(\n",
    "            mc_trial_rows['conn_ub'].to_numpy().reshape(-1, 1),\n",
    "            (1, n_radii)\n",
    "        )\n",
    "        conn_cmp_arr = np.tile(rads, (conn_thresh_arr.shape[0], 1))\n",
    "\n",
    "    above_threshold = conn_cmp_arr >= conn_thresh_arr\n",
    "    estimates = np.sum(above_threshold, axis=0) / len(mc_trial_rows)\n",
    "    estimate_dict[(prm_type, _clearance, dim, n_samples)] = estimates"
   ],
   "id": "e372cfa7cf11abe5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Plotting results:\n",
    "This isn't the final version of the plot (since we need to tabulate the data anyway because there is too much otherwise),\n",
    "but these line plots is a good way to understand how the empirical probability changes as the\n",
    "radius changes.\n",
    "\n",
    "We'll also compare against the theoretical bound too. We'll work with the feasibility version.\n",
    "For passage of clearance $\\delta$, then we'll require a $\\delta/4$-net and a connection radius\n",
    "of $2\\delta$. \n",
    "\n",
    "If the largest radius turns out to be smaller than $2\\delta$, then we'll just compute\n",
    "the bound for the corresponding smaller net (as dictated by the radius). We'll need to expect some\n",
    "looseness for that scenario. NOTE: We tried this, and it turns out the numerical bound computation is vacuous in this scenario. Even just using the largest net rad as dictated by the environment is off by a full order of magnitude."
   ],
   "id": "9f6d96b056639a86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:44:23.679452Z",
     "start_time": "2024-05-30T14:43:21.066772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nonasymptotic.bound import compute_sauer_shelah_bound_log2, compute_vol_unit_sphere\n",
    "from nonasymptotic.envs import NarrowPassage\n",
    "\n",
    "# recompile the results into a dataframe and then use seaborn to plot.\n",
    "# the most efficient way to do this is to set up each array separately and then concatenate\n",
    "plot_dfs = []\n",
    "for prm_type, _clearance, dim, n_samples in estimate_dict.keys():\n",
    "    clearance = float(_clearance)\n",
    "    estimates = estimate_dict[(prm_type, _clearance, dim, n_samples)]  \n",
    "   \n",
    "    # if the estimate is nan, then it hasn't been processed yet by the experiments. so we skip.\n",
    "    if np.isnan(estimates[-1]):\n",
    "        continue\n",
    "      \n",
    "    # put estimates format amenable for dataframe\n",
    "    dict_for_df = {\n",
    "        \"p\": estimates,\n",
    "        \"conn\": np.arange(max_knn) if prm_type == 'knn' else rads,\n",
    "        \"p_type\": [\"estimated\"] * max_knn if prm_type == 'knn' else [\"estimated\"] * n_radii,\n",
    "    }\n",
    "    \n",
    "    if prm_type == 'radius':\n",
    "        # compute corresponding theoretical quantities (using smallest Sauer-Shelah expression)\n",
    "        vol_env = NarrowPassage(dim, clearance, seed=1999).vol\n",
    "        net_rads = np.array([clearance / 4] * n_radii) #np.minimum(rads / 8, clearance / 4) # clip for net radius corresponding to clearance of the passage\n",
    "        rhos = (compute_vol_unit_sphere(dim) / vol_env) * (net_rads ** dim)\n",
    "        log2_ss_probs = np.array([compute_sauer_shelah_bound_log2(n_samples, _rho, dim + 1) for _rho in rhos])\n",
    "        ss_probs = 2 ** log2_ss_probs\n",
    "        dict_for_df['p'] = np.concatenate([dict_for_df['p'], ss_probs])\n",
    "        dict_for_df['conn'] = np.concatenate([dict_for_df['conn'], rads])\n",
    "        dict_for_df['p_type'] += [\"theory\"] * n_radii\n",
    "    \n",
    "    # construct dataframe\n",
    "    _df = pd.DataFrame(dict_for_df)\n",
    "    _df['prm_type'] = prm_type\n",
    "    _df['clearance'] = _clearance\n",
    "    _df['dim'] = dim\n",
    "    _df['n_samples'] = n_samples\n",
    "    plot_dfs.append(_df)\n",
    "plot_df = pd.concat(plot_dfs)    \n",
    "\n",
    "# in this scenario, it makes sense to plot knn and radius prms separately\n",
    "radius_plot_df = plot_df[plot_df['prm_type'] == 'radius']\n",
    "knn_plot_df = plot_df[plot_df['prm_type'] == 'knn']\n",
    "\n",
    "plt.figure()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.relplot(data=radius_plot_df, x='conn', y='p', row='dim', col='clearance', hue='n_samples',  style='p_type',\n",
    "            kind='line', palette=sns.color_palette(\"pastel\"))\n",
    "plt.title('Radius MC Experiments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.relplot(data=knn_plot_df, x='conn', y='p', row='dim', col='clearance', hue='n_samples',  style='p_type',\n",
    "            kind='line', palette=sns.color_palette(\"pastel\"))\n",
    "plt.title('KNN MC Experiments')\n",
    "plt.show()"
   ],
   "id": "c7aef719e732c044",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 29\u001B[0m\n\u001B[1;32m     27\u001B[0m net_rads \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([clearance \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m*\u001B[39m n_radii) \u001B[38;5;66;03m#np.minimum(rads / 8, clearance / 4) # clip for net radius corresponding to clearance of the passage\u001B[39;00m\n\u001B[1;32m     28\u001B[0m rhos \u001B[38;5;241m=\u001B[39m (compute_vol_unit_sphere(dim) \u001B[38;5;241m/\u001B[39m vol_env) \u001B[38;5;241m*\u001B[39m (net_rads \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m dim)\n\u001B[0;32m---> 29\u001B[0m log2_ss_probs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([compute_sauer_shelah_bound_log2(n_samples, _rho, dim \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m _rho \u001B[38;5;129;01min\u001B[39;00m rhos])\n\u001B[1;32m     30\u001B[0m ss_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m log2_ss_probs\n\u001B[1;32m     31\u001B[0m dict_for_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([dict_for_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m'\u001B[39m], ss_probs])\n",
      "Cell \u001B[0;32mIn[9], line 29\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     27\u001B[0m net_rads \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([clearance \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m*\u001B[39m n_radii) \u001B[38;5;66;03m#np.minimum(rads / 8, clearance / 4) # clip for net radius corresponding to clearance of the passage\u001B[39;00m\n\u001B[1;32m     28\u001B[0m rhos \u001B[38;5;241m=\u001B[39m (compute_vol_unit_sphere(dim) \u001B[38;5;241m/\u001B[39m vol_env) \u001B[38;5;241m*\u001B[39m (net_rads \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m dim)\n\u001B[0;32m---> 29\u001B[0m log2_ss_probs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mcompute_sauer_shelah_bound_log2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_rho\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _rho \u001B[38;5;129;01min\u001B[39;00m rhos])\n\u001B[1;32m     30\u001B[0m ss_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m log2_ss_probs\n\u001B[1;32m     31\u001B[0m dict_for_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([dict_for_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m'\u001B[39m], ss_probs])\n",
      "File \u001B[0;32m~/Research/nonasymptotic-mp/nonasymptotic/bound.py:32\u001B[0m, in \u001B[0;36mcompute_sauer_shelah_bound_log2\u001B[0;34m(m_samples, rho, vc_dim)\u001B[0m\n\u001B[1;32m     27\u001B[0m ss_comb_sum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum([scipy\u001B[38;5;241m.\u001B[39mspecial\u001B[38;5;241m.\u001B[39mcomb(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m m_samples, _d, exact\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m _d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(vc_dim \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)])\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# to dodge some numerical imprecision of the exponentiation, let's do the calculation\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m#   in 2-logspace. math.log2 doesn't convert to float (unlike numpy), so we use that here.\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m log2_prob \u001B[38;5;241m=\u001B[39m \u001B[43mmath\u001B[49m\u001B[38;5;241m.\u001B[39mlog2(ss_comb_sum) \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m-\u001B[39mrho \u001B[38;5;241m*\u001B[39m m_samples \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m log2_prob\n",
      "File \u001B[0;32m~/Research/nonasymptotic-mp/nonasymptotic/bound.py:32\u001B[0m, in \u001B[0;36mcompute_sauer_shelah_bound_log2\u001B[0;34m(m_samples, rho, vc_dim)\u001B[0m\n\u001B[1;32m     27\u001B[0m ss_comb_sum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum([scipy\u001B[38;5;241m.\u001B[39mspecial\u001B[38;5;241m.\u001B[39mcomb(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m m_samples, _d, exact\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m _d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(vc_dim \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)])\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# to dodge some numerical imprecision of the exponentiation, let's do the calculation\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m#   in 2-logspace. math.log2 doesn't convert to float (unlike numpy), so we use that here.\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m log2_prob \u001B[38;5;241m=\u001B[39m \u001B[43mmath\u001B[49m\u001B[38;5;241m.\u001B[39mlog2(ss_comb_sum) \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m-\u001B[39mrho \u001B[38;5;241m*\u001B[39m m_samples \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m log2_prob\n",
      "File \u001B[0;32m/snap/pycharm-professional/391/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/snap/pycharm-professional/391/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/391/plugins/python/helpers/pydev/pydevd.py:1187\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1184\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1187\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/391/plugins/python/helpers/pydev/pydevd.py:1202\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1201\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1202\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T14:37:04.157744Z",
     "start_time": "2024-05-30T14:37:04.155803Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ac0ed76c60ed5dd",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
